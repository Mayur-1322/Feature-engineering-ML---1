{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**(MACHINE LEARNING) ASSIGNMENT NO - 1 =Feature\n",
        "Engineering**"
      ],
      "metadata": {
        "id": "z27gsgyk5fHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?"
      ],
      "metadata": {
        "id": "aLGxDLEe5yD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning and statistics, a parameter is a value that defines a model's behavior and is learned during training. For example, in a linear regression model, the slope (\n",
        "ùëö\n",
        "m) and intercept (\n",
        "ùëè\n",
        "b) of the line are parameters."
      ],
      "metadata": {
        "id": "sRQb7LsV6HZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation?\n",
        "What does negative corelation mean?"
      ],
      "metadata": {
        "id": "_IPzvPw96I6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation measures the relationship and dependency between two variables. It quantifies how the change in one variable is associated with the change in another. The correlation coefficient ranges from -1 to 1:\n",
        "\n",
        "+\n",
        "1\n",
        "+1: Perfect positive correlation.\n",
        "‚àí\n",
        "1\n",
        "‚àí1: Perfect negative correlation.\n",
        "0\n",
        "0: No correlation."
      ],
      "metadata": {
        "id": "ptmR2QdB6KBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative correlation indicates an inverse relationship between two variables. When one variable increases, the other tends to decrease, and vice versa. For example, the correlation between the price of a product and its demand is often negative: as the price rises, demand typically falls."
      ],
      "metadata": {
        "id": "ZBhjrfPc6LfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?"
      ],
      "metadata": {
        "id": "oZYmIiA86hEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning is a subset of artificial intelligence that allows systems to learn from data and improve their performance on a specific task without being explicitly programmed.\n",
        "\n",
        "Main components of Machine Learning:\n",
        "\n",
        "Data: The raw input used to train the model.\n",
        "Features: Relevant attributes extracted from the data.\n",
        "Model: The algorithm or structure that learns patterns in the data.\n",
        "Loss Function: Measures how well the model's predictions align with the actual outcomes.\n",
        "Optimization Algorithm: Updates model parameters to minimize the loss.\n",
        "Training: The process of teaching the model using data.\n",
        "Evaluation: Assessing the model's performance on unseen data."
      ],
      "metadata": {
        "id": "DKlXwSdm6sVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?"
      ],
      "metadata": {
        "id": "4fbgoWAR6wCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss value quantifies the difference between the model's predictions and the actual data:\n",
        "\n",
        "A low loss value indicates the model is making accurate predictions and fits the data well.\n",
        "A high loss value suggests the model has poor predictive performance. The loss function helps guide the training process to improve the model iteratively."
      ],
      "metadata": {
        "id": "lA3MchRr6y8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: Variables that can take any numerical value within a range. Example: Height, weight, or temperature.\n",
        "Categorical variables: Variables that represent distinct categories or groups. Example: Gender (Male/Female), Color (Red/Green/Blue)."
      ],
      "metadata": {
        "id": "NYnoklzc6z0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Categorical variables must be converted into numerical representations for machine learning models. Common techniques include:\n",
        "\n",
        "One-Hot Encoding: Converts categories into binary vectors (e.g., \"Red,\" \"Green,\" \"Blue\" ‚Üí [1,0,0], [0,1,0], [0,0,1]).\n",
        "Label Encoding: Assigns a unique integer to each category (e.g., \"Red\" ‚Üí 1, \"Green\" ‚Üí 2, \"Blue\" ‚Üí 3).\n",
        "Target Encoding: Replaces categories with their average target value.\n",
        "Frequency Encoding: Maps categories to their frequency in the dataset.\n"
      ],
      "metadata": {
        "id": "8v6vNfPk7eGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "Training Dataset: A subset of data used to teach the model by adjusting its parameters.\n",
        "Testing Dataset: A separate subset used to evaluate the model's performance on unseen data, ensuring it generalizes well."
      ],
      "metadata": {
        "id": "DhDZ5bU57kUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module in the Scikit-learn library that provides tools for preparing data before training a model. It includes functions for:\n",
        "\n",
        "Scaling and normalizing data.\n",
        "Encoding categorical variables.\n",
        "Handling missing values.\n",
        "Transforming features (e.g., polynomial expansion)"
      ],
      "metadata": {
        "id": "4hJATiu87ne4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test Set?\n",
        "\n",
        "\n",
        "A Test Set is a portion of the dataset set aside to evaluate the model's performance after training. It helps measure how well the model generalizes to unseen data and avoids overfitting."
      ],
      "metadata": {
        "id": "IjixQJRL7p34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "yU8vSVen8rj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We typically use the train_test_split function from Scikit-learn. This function randomly splits the dataset into training and testing subsets."
      ],
      "metadata": {
        "id": "rExTxqG-8v0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "collapsed": true,
        "id": "auys6iP284mS",
        "outputId": "e95b1269-0d52-4607-abeb-51c9b7dabb90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-89e5fbc1664a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X: Features.\n",
        "y: Target variable.\n",
        "test_size: Proportion of the dataset to include in the test split.\n",
        "random_state: Seed for reproducibility"
      ],
      "metadata": {
        "id": "rH7bh9qq9EDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "Exploratory Data Analysis (EDA) helps in:\n",
        "\n",
        "Understanding data distribution, patterns, and relationships.\n",
        "Identifying missing values and outliers.\n",
        "Detecting correlations between features.\n",
        "Deciding on feature engineering and preprocessing steps.\n",
        "EDA ensures the data is clean, relevant, and suitable for modeling.\n"
      ],
      "metadata": {
        "id": "LFIgGwZM9FXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "\n",
        "Correlation measures the strength and direction of the linear relationship between two variables, ranging from -1 to 1:\n",
        "\n",
        "+1: Perfect positive relationship.\n",
        "0: No linear relationship.\n",
        "-1: Perfect negative relationship."
      ],
      "metadata": {
        "id": "LZRb-u-l9Qy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "\n",
        "Negative correlation indicates an inverse relationship between two variables: as one increases, the other decreases. For instance, as temperature rises, the need for heating reduces."
      ],
      "metadata": {
        "id": "c4SVcHRu9Sp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?"
      ],
      "metadata": {
        "id": "QFhRDAPV9Uhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use pandas or numpy to calculate correlations. Example with Pandas:"
      ],
      "metadata": {
        "id": "-cnwhour9kWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "hsn4mLws9leR",
        "outputId": "bc23364a-640e-4bb9-82bc-e555355e39cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6067733bda5a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorrelation_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Difference between correlation and causation?\n",
        "\n",
        "\n",
        "Causation: A change in one variable directly causes a change in another.\n",
        "Correlation: Two variables move together, but one may not necessarily cause the other.\n",
        "Example:\n",
        "\n",
        "Correlation: Ice cream sales and drowning incidents are positively correlated (summer).\n",
        "Causation: Higher temperatures cause people to swim, increasing drowning incidents"
      ],
      "metadata": {
        "id": "0TjRHa_K-Gmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? Types of optimizers?\n",
        "\n",
        "An Optimizer is an algorithm that minimizes the loss function by adjusting model parameters.\n",
        "\n",
        "Types of optimizers:\n",
        "\n",
        "Gradient Descent: Simple iterative optimization.\n",
        "Stochastic Gradient Descent (SGD): Updates parameters using a single sample.\n",
        "Adam: Combines momentum and RMSProp for faster convergence.\n",
        "RMSProp: Uses moving averages to adjust learning rates.\n",
        "Example (Adam in TensorFlow):"
      ],
      "metadata": {
        "id": "VGE0vRuL-JVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n"
      ],
      "metadata": {
        "id": "0x8kZrY0-MS-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model?\n",
        "\n",
        "The sklearn.linear_model module in Scikit-learn provides linear modeling algorithms such as:\n",
        "\n",
        "Linear Regression.\n",
        "Logistic Regression.\n",
        "Ridge and Lasso Regression.\n",
        "Example:"
      ],
      "metadata": {
        "id": "tQhYq74Q-Opt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n"
      ],
      "metadata": {
        "id": "I0tFRcHf-RjR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "model.fit() trains the model on the given dataset by learning patterns.\n",
        "Arguments:\n",
        "\n",
        "X_train: Feature matrix.\n",
        "y_train: Target variable.\n",
        "Example:"
      ],
      "metadata": {
        "id": "FFXvSp4H-T3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "collapsed": true,
        "id": "wyIrqPGw-Xfg",
        "outputId": "3d8a7989-ab3b-4f28-c060-0c3ebd8b1c60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d768f88d541e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "model.predict() makes predictions based on the trained model.\n",
        "Arguments:\n",
        "\n",
        "X_test: Input data for prediction.\n",
        "Example:"
      ],
      "metadata": {
        "id": "VLdFqK29-Z4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "hXxcSGfr-ehK",
        "outputId": "928c08db-e402-43e6-ac57-8be74d990add"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0e147a3957b1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: Numerical values that can take any range (e.g., height, weight).\n",
        "Categorical variables: Discrete categories or groups (e.g., gender, colors)."
      ],
      "metadata": {
        "id": "h8hv5peP-irM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling normalizes feature values to a common scale. It improves model performance, especially for algorithms sensitive to feature magnitude (e.g., SVMs, KNN, Gradient Descent).\n",
        "Techniques: Standardization, Min-Max Scaling."
      ],
      "metadata": {
        "id": "KBzb0v0a-nh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "\n",
        "Using Scikit-learn's preprocessing module:"
      ],
      "metadata": {
        "id": "u7mAl6Qj-p3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "A5ZsRsYh-r5D",
        "outputId": "b68e034a-de85-4ae7-e812-01fea8f3f596"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d6da406c9b16>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing provides tools for data preprocessing, including:\n",
        "\n",
        "Encoding categorical variables.\n",
        "Scaling and normalizing data.\n",
        "Handling missing values."
      ],
      "metadata": {
        "id": "4mg8H4v4-xWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.How do we split data for model fitting (training and testing) in Python?"
      ],
      "metadata": {
        "id": "kRgDQW3q_DfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This ensures that the model is trained on one subset of the data and evaluated on another, allowing you to assess its performance on unseen data."
      ],
      "metadata": {
        "id": "XQfYrvc3_F4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset\n",
        "X = [[1], [2], [3], [4], [5]]  # Features\n",
        "y = [1, 2, 3, 4, 5]           # Labels/target\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training Features:\", X_train)\n",
        "print(\"Testing Features:\", X_test)\n",
        "print(\"Training Labels:\", y_train)\n",
        "print(\"Testing Labels:\", y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_XrdLZR_MPl",
        "outputId": "a16c4a8b-8b18-471a-8ec1-a8e28221c178"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features: [[5], [3], [1], [4]]\n",
            "Testing Features: [[2]]\n",
            "Training Labels: [5, 3, 1, 4]\n",
            "Testing Labels: [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters of train_test_split:\n",
        "test_size: Proportion of the dataset to include in the test split (e.g., 0.2 means 20% of the data is for testing).\n",
        "train_size: Proportion of the dataset to include in the training split (optional; complements test_size).\n",
        "random_state: Ensures reproducibility by controlling the shuffling process.\n",
        "shuffle: Whether to shuffle the data before splitting (default is True)"
      ],
      "metadata": {
        "id": "64IQNACF_X-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Manual Splitting:\n",
        "You can also split the data manually if you don‚Äôt want to use libraries:"
      ],
      "metadata": {
        "id": "M4rZDv5B_ZYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "data = np.array([1, 2, 3, 4, 5])\n",
        "labels = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Shuffle and split indices\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_size = int(0.8 * len(data))  # 80% for training\n",
        "train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test = data[train_indices], data[test_indices]\n",
        "y_train, y_test = labels[train_indices], labels[test_indices]\n",
        "\n",
        "print(\"Training Data:\", X_train)\n",
        "print(\"Testing Data:\", X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgfLF1ox_bc7",
        "outputId": "fe6b7990-b4cd-4cb4-ead1-c5fef9738949"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: [4 2 1 3]\n",
            "Testing Data: [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Advanced Splitting Techniques:\n",
        "For more sophisticated scenarios, you can use:\n",
        "\n",
        "Stratified Splitting: Ensures class proportions are preserved in the splits (use stratify=y in train_test_split).\n",
        "Cross-Validation: Divides the data into multiple folds for training and validation"
      ],
      "metadata": {
        "id": "N6QwA7L3_pSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hyQqBrH_uwp",
        "outputId": "5eb5b02d-4615-4b9b-c63a-2b1f949ee4ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train indices: [1 2 3 4] Test indices: [0]\n",
            "Train indices: [0 2 3 4] Test indices: [1]\n",
            "Train indices: [0 1 3 4] Test indices: [2]\n",
            "Train indices: [0 1 2 4] Test indices: [3]\n",
            "Train indices: [0 1 2 3] Test indices: [4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain data encoding?"
      ],
      "metadata": {
        "id": "KQ_YBECi_3a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Encoding: Data encoding is the process of converting categorical or textual data into numerical format so that it can be understood and processed by machine learning algorithms.\n",
        "\n",
        "Some Key points :-\n",
        "\n",
        "Label Encoding: Converts categories to integers. Use for ordered data but beware of implying false order.\n",
        "\n",
        "One-Hot Encoding: Converts categories to binary vectors. Best for unordered categories but increases dimensionality.\n",
        "\n",
        "Ordinal Encoding: Maps categories to meaningful ordinal values. Use when categories have a natural order.\n",
        "\n",
        "Frequency/Count Encoding: Replaces categories with their frequency or count. Useful for large categories.\n",
        "\n",
        "Target Encoding: Maps categories to the mean of the target variable. Avoid data leakage by encoding during cross-validation.\n",
        "\n",
        "Binary Encoding: Converts categories into binary format, reducing dimensionality compared to one-hot."
      ],
      "metadata": {
        "id": "J4ewrcyz_9xq"
      }
    }
  ]
}